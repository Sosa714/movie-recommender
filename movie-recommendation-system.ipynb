{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports and Constants Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"movies.csv\"))\n",
    "ratings_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"ratings.csv\")).iloc[:500000, :] # Using 500,000 for now due to sheer size of original\n",
    "tags_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"tags.csv\"))\n",
    "genome_scores_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"genome-scores.csv\"))\n",
    "genome_tags_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"genome-tags.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the movies' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62423 entries, 0 to 62422\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  62423 non-null  int64 \n",
      " 1   title    62423 non-null  object\n",
      " 2   genres   62423 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the movies' dataset:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the movies' dataset: (62423, 3)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the movies' dataset:\n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the movies' dataset:\")\n",
    "print(movies_df.info())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the movies' dataset:\")\n",
    "print(movies_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the movies' dataset:\", movies_df.shape)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the movies' dataset:\")\n",
    "print(movies_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the ratings' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     500000 non-null  int64  \n",
      " 1   movieId    500000 non-null  int64  \n",
      " 2   rating     500000 non-null  float64\n",
      " 3   timestamp  500000 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 15.3 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the ratings' dataset:\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the ratings' dataset: (500000, 4)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the ratings' dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the ratings' dataset:\")\n",
    "print(ratings_df.info())\n",
    "# Timestamp unnecessary\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the ratings' dataset:\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the ratings' dataset:\", ratings_df.shape)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the ratings' dataset:\")\n",
    "print(ratings_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the tags' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1093360 entries, 0 to 1093359\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   userId     1093360 non-null  int64 \n",
      " 1   movieId    1093360 non-null  int64 \n",
      " 2   tag        1093344 non-null  object\n",
      " 3   timestamp  1093360 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 33.4+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the tags' dataset:\n",
      "   userId  movieId               tag   timestamp\n",
      "0       3      260           classic  1439472355\n",
      "1       3      260            sci-fi  1439472256\n",
      "2       4     1732       dark comedy  1573943598\n",
      "3       4     1732    great dialogue  1573943604\n",
      "4       4     7569  so bad it's good  1573943455\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the tags' dataset: (1093360, 4)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the tags' dataset:\n",
      "userId        0\n",
      "movieId       0\n",
      "tag          16\n",
      "timestamp     0\n",
      "dtype: int64\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Unique values tags' in dataset:\n",
      "73050\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the tags' dataset:\")\n",
    "print(tags_df.info())\n",
    "# Timestamp unnecessary\n",
    "# Tags are user defined, so a lot of them (although the same) will be spelled differently. \n",
    "    # i.e. sci-fi vs scifi, 90's vs 90s, and Horror vs horror\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the tags' dataset:\")\n",
    "print(tags_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the tags' dataset:\", tags_df.shape)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the tags' dataset:\")\n",
    "print(tags_df.isnull().sum())\n",
    "# 16 missing values\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nUnique values tags' in dataset:\")\n",
    "print(tags_df.tag.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Preprocessing for Ratings, and Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n",
      "   userId  movieId  rating\n",
      "0       1      296     5.0\n",
      "2       1      307     5.0\n",
      "3       1      665     5.0\n",
      "5       1     1088     4.0\n",
      "8       1     1237     5.0\n"
     ]
    }
   ],
   "source": [
    "print(ratings_df.head())\n",
    "ratings_cleaned = ratings_df.copy()\n",
    "ratings_cleaned = ratings_cleaned.drop(columns=['timestamp'])\n",
    "ratings_cleaned = ratings_cleaned[ratings_cleaned['rating'] >= 4.0]\n",
    "print(ratings_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tags(tag):\n",
    "    \"\"\"Preprocess tags by lowercasing, removing parentheses, hyphens, and 'based'.\"\"\"\n",
    "    if pd.isna(tag):\n",
    "        return tag  # Return NaN as is\n",
    "    tag = tag.lower()\n",
    "    tag = re.sub(r'\\(.*?\\)', '', tag)\n",
    "    tag = tag.replace('-', '')\n",
    "    return tag.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId               tag   timestamp\n",
      "0       3      260           classic  1439472355\n",
      "1       3      260            sci-fi  1439472256\n",
      "2       4     1732       dark comedy  1573943598\n",
      "3       4     1732    great dialogue  1573943604\n",
      "4       4     7569  so bad it's good  1573943455\n",
      "   userId  movieId               tag\n",
      "0       3      260           classic\n",
      "1       3      260             scifi\n",
      "2       4     1732       dark comedy\n",
      "3       4     1732    great dialogue\n",
      "4       4     7569  so bad it's good\n"
     ]
    }
   ],
   "source": [
    "tags_cleaned = tags_df.copy()\n",
    "print(tags_df.head())\n",
    "\n",
    "tags_cleaned = tags_cleaned.drop(columns=['timestamp'])\n",
    "tags_cleaned = tags_cleaned.dropna()\n",
    "\n",
    "tags_cleaned['tag'] = tags_cleaned['tag'].apply(preprocess_tags)\n",
    "tags_cleaned = tags_cleaned[~tags_cleaned['tag'].str.contains('based', na=False)]\n",
    "print(tags_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_movies(genre):\n",
    "    \"\"\"Convert genre strings into lowercase.\"\"\"\n",
    "    return genre.lower()  # Make sure to return the processed genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  adventure|animation|children|comedy|fantasy  \n",
      "1                   adventure|children|fantasy  \n",
      "2                               comedy|romance  \n",
      "3                         comedy|drama|romance  \n",
      "4                                       comedy  \n"
     ]
    }
   ],
   "source": [
    "movies_cleaned = movies_df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "print(movies_df.head())\n",
    "\n",
    "movies_cleaned['genres'] = movies_cleaned['genres'].apply(preprocess_movies)\n",
    "print(movies_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets to create Movies-based dataset, movies_genres&tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating initial movies_genres&tags dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                         genres&tags  \n",
      "0  heroic mission|engaging|fun family movie|fanta...  \n",
      "1  kirsten dunst|fiction|adaptation of book|magic...  \n",
      "2  no_fa_ganes|walter matthau|moldy|daryl hannah|...  \n",
      "3  single mother|clv|romance|chick flick|drama|di...  \n",
      "4  fantasy|steve martin|comedy|parent child relat...  \n"
     ]
    }
   ],
   "source": [
    "# Merge movies and tags data\n",
    "merged_data = pd.merge(movies_cleaned, tags_cleaned, on='movieId', how='left')\n",
    "def combine_and_deduplicate(group):\n",
    "    # Combine all genres and tags for each group (movie)\n",
    "    all_genres = group['genres'].iloc[0].split('|') if pd.notna(group['genres'].iloc[0]) else []\n",
    "    all_tags = group['tag'].dropna().tolist()\n",
    "    combined = list(set(all_genres + all_tags))  # Remove duplicates\n",
    "    return '|'.join(combined)\n",
    "\n",
    "# Apply the function to each group\n",
    "movies_genres_tags = merged_data.groupby('movieId').apply(combine_and_deduplicate).reset_index(name='genres&tags')\n",
    "\n",
    "# Merge with movies_cleaned to get titles\n",
    "movies_genres_tags = pd.merge(movies_cleaned[['movieId', 'title']], movies_genres_tags, on='movieId')\n",
    "\n",
    "print(movies_genres_tags.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding relevance scores for each genre/tag to the movies-based dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge genome scores and tags\n",
    "genome_combined = pd.merge(genome_scores_df, genome_tags_df, on='tagId')\n",
    "\n",
    "# Creating a dictionary for quick relevance score lookup\n",
    "genome_dict = genome_combined.set_index(['movieId', 'tag'])['relevance'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find relevance scores using the dictionary\n",
    "def find_relevance_scores(row):\n",
    "    genres_tags = row['genres&tags'].split('|')\n",
    "    scores = [genome_dict.get((row['movieId'], tag), 0) for tag in genres_tags]\n",
    "    # Filter out scores below 0.6 and corresponding tags/genres\n",
    "    filtered_data = [(tag, score) for tag, score in zip(genres_tags, scores) if score >= 0.7]\n",
    "    if filtered_data:\n",
    "        filtered_tags, filtered_scores = zip(*filtered_data)\n",
    "        return '|'.join(filtered_tags), ','.join(map(str, filtered_scores))\n",
    "    else:\n",
    "        return '', ''\n",
    "\n",
    "# Apply the function to movies_genres_tags\n",
    "movies_genres_tags[['genres&tags', 'relevance_scores']] = movies_genres_tags.apply(\n",
    "    find_relevance_scores, axis=1, result_type='expand')\n",
    "\n",
    "# Save the updated dataset in the data folder\n",
    "movies_genres_tags.to_csv('data/movies_genres&tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets to create users-based dataset, users_liked_genres&tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ratings_cleaned with movies_cleaned\n",
    "user_movies_genres = pd.merge(ratings_cleaned, movies_cleaned, on='movieId')\n",
    "\n",
    "# Merge the above with tags_cleaned\n",
    "user_movies_genres_tags = pd.merge(user_movies_genres, tags_cleaned, on=['userId', 'movieId'], how='left')\n",
    "\n",
    "# Function to concatenate genres and user-specific tags\n",
    "def concatenate_user_genres_tags(group):\n",
    "    genres = '|'.join(group['genres'])\n",
    "    tags = '|'.join(group['tag'].dropna().unique())  # Drop NA and get unique tags\n",
    "    return genres + ('|' + tags if tags else '')  # Combine genres and tags, separated by '|'\n",
    "\n",
    "# Aggregate genres and tags for each user\n",
    "users_liked_genres_tags = user_movies_genres_tags.groupby('userId').apply(concatenate_user_genres_tags).reset_index(name='liked_genres&tags')\n",
    "\n",
    "users_liked_genres_tags.to_csv('data/users_liked_genres&tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Returning Recommendations to User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on Toy Story, we would recommend:\n",
      "Movie A\n",
      "Movie E\n",
      "Movie D\n",
      "\n",
      "Based on Hunchback, we would recommend:\n",
      "Movie A\n",
      "Movie E\n",
      "\n",
      "Based on John Wick, we would recommend:\n",
      "Movie E\n",
      "Movie A\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sample 2D array [[movie_names], [tags_embeddings]]\n",
    "sample_2D_array = [['Movie A', 'Movie B', 'Movie C', 'Movie D', 'Movie E', 'Toy Story', 'Hunchback', 'John Wick'],\n",
    "    [\n",
    "        np.mean([[0.1, 0.2, 0.3], [0.4, 0.3, 0.5]], axis=0),\n",
    "        np.mean([[0.3, 0.6, 0.1], [0.2, 0.1, 0.4]], axis=0),\n",
    "        np.mean([[0.5, 0.8, 0.5], [0.1, 0.3, 0.3]], axis=0),\n",
    "        np.mean([[0.2, 0.2, 0.2], [0.3, 0.5, 0.6]], axis=0),\n",
    "        np.mean([[0.7, 0.8, 0.9], [0.2, 0.1, 0.2]], axis=0),\n",
    "        np.mean([[0.1, 0.2, 0.3], [0.4, 0.3, 0.5]], axis=0),\n",
    "        np.mean([[0.1, 0.2, 0.3], [0.6, 0.2, 0.8]], axis=0),\n",
    "        np.mean([[0.9, 0.1, 0.4], [0.3, 0.8, 0.7]], axis=0)\n",
    "    ]]\n",
    "\n",
    "# User's liked movies 2D array\n",
    "user_2D_array = [['Toy Story', 'Hunchback', 'John Wick'],\n",
    "    [\n",
    "        np.mean([[0.1, 0.2, 0.3], [0.4, 0.3, 0.5]], axis=0),\n",
    "        np.mean([[0.1, 0.2, 0.3], [0.6, 0.2, 0.8]], axis=0),\n",
    "        np.mean([[0.9, 0.1, 0.4], [0.3, 0.8, 0.7]], axis=0)\n",
    "    ]]\n",
    "\n",
    "# Creating constant names for better clarity\n",
    "sample_movies = sample_2D_array[0]\n",
    "sample_tag_embeddings = sample_2D_array[1]\n",
    "\n",
    "user_movies = user_2D_array[0]\n",
    "user_tag_embeddings = user_2D_array[1]\n",
    "\n",
    "# Convert tag embeddings to a 2D NumPy array\n",
    "X_sample = np.array(sample_tag_embeddings)\n",
    "X_user = np.array(user_tag_embeddings)\n",
    "\n",
    "# Create and fit the model with cosine similarity using 10 closest movies\n",
    "# (4 in this example as there are not 10 other movies)\n",
    "knn = NearestNeighbors(n_neighbors=4, metric='cosine')\n",
    "knn.fit(X_sample)\n",
    "\n",
    "# Find 4 movies similar to the query movie\n",
    "recommendations = []\n",
    "for test in X_user:\n",
    "    distances, indices = knn.kneighbors([test])\n",
    "\n",
    "    # Filter out movies that are already liked by the user\n",
    "    similar_movies = [sample_movies[i] for i in indices[0] if sample_movies[i] not in user_movies]\n",
    "    recommendations.append(similar_movies)\n",
    "\n",
    "# Print the similar movies\n",
    "for i, user_movie in enumerate(user_movies):\n",
    "    print(f\"Based on {user_movie}, we would recommend:\")\n",
    "    for recommended_movie in recommendations[i]:\n",
    "        print(recommended_movie)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embedding_dim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_embedding\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Apply the function to calculate average embeddings for each movie\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m movies_genres_tags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mmovies_genres_tags\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgenres&tags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m|\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mglove_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4630\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[0;32m   4520\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4521\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4522\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4525\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4526\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4527\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4528\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4529\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1025\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_str()\n\u001b[0;32m   1024\u001b[0m \u001b[38;5;66;03m# self.f is Callable\u001b[39;00m\n\u001b[1;32m-> 1025\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1076\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1074\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1075\u001b[0m         values \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m)\u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m-> 1076\u001b[0m         mapped \u001b[38;5;241m=\u001b[39m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1077\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1078\u001b[0m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m            \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1083\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\tomas\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\lib.pyx:2834\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[24], line 28\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m avg_embedding\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Apply the function to calculate average embeddings for each movie\u001b[39;00m\n\u001b[0;32m     27\u001b[0m movies_genres_tags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie_embedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m movies_genres_tags[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres&tags\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\n\u001b[1;32m---> 28\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m x: average_embedding(x\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m'\u001b[39m), glove_embeddings, \u001b[43membedding_dim\u001b[49m)\n\u001b[0;32m     29\u001b[0m )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embedding_dim' is not defined"
     ]
    }
   ],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "glove_file_path = 'data/glove.6B.50d.txt'\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path)\n",
    "\n",
    "# Access the embedding for a specific word\n",
    "embedding_for_word = glove_embeddings.get('word', np.zeros(50))  #50 is the dimensionality for the embeddings\n",
    "\n",
    "\n",
    "embedding_dim = 50\n",
    "# Create a function to calculate the average word embedding for a list of tags\n",
    "def average_embedding(tags, embeddings_dict, embedding_dim):\n",
    "    embeddings = [embeddings_dict.get(tag, np.zeros(embedding_dim)) for tag in tags]\n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    return avg_embedding\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
