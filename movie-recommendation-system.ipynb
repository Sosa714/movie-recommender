{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports and Constants Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"movies.csv\"))\n",
    "ratings_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"ratings.csv\")).iloc[:500000, :] # Using 500,000 for now due to sheer size of original\n",
    "tags_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"tags.csv\"))\n",
    "genome_scores_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"genome-scores.csv\"))\n",
    "genome_tags_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"genome-tags.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the movies' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62423 entries, 0 to 62422\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  62423 non-null  int64 \n",
      " 1   title    62423 non-null  object\n",
      " 2   genres   62423 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the movies' dataset:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the movies' dataset: (62423, 3)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the movies' dataset:\n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the movies' dataset:\")\n",
    "print(movies_df.info())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the movies' dataset:\")\n",
    "print(movies_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the movies' dataset:\", movies_df.shape)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the movies' dataset:\")\n",
    "print(movies_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the ratings' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     500000 non-null  int64  \n",
      " 1   movieId    500000 non-null  int64  \n",
      " 2   rating     500000 non-null  float64\n",
      " 3   timestamp  500000 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 15.3 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the ratings' dataset:\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the ratings' dataset: (500000, 4)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the ratings' dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the ratings' dataset:\")\n",
    "print(ratings_df.info())\n",
    "# Timestamp unnecessary\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the ratings' dataset:\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the ratings' dataset:\", ratings_df.shape)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the ratings' dataset:\")\n",
    "print(ratings_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the tags' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1093360 entries, 0 to 1093359\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   userId     1093360 non-null  int64 \n",
      " 1   movieId    1093360 non-null  int64 \n",
      " 2   tag        1093344 non-null  object\n",
      " 3   timestamp  1093360 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 33.4+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the tags' dataset:\n",
      "   userId  movieId               tag   timestamp\n",
      "0       3      260           classic  1439472355\n",
      "1       3      260            sci-fi  1439472256\n",
      "2       4     1732       dark comedy  1573943598\n",
      "3       4     1732    great dialogue  1573943604\n",
      "4       4     7569  so bad it's good  1573943455\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the tags' dataset: (1093360, 4)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the tags' dataset:\n",
      "userId        0\n",
      "movieId       0\n",
      "tag          16\n",
      "timestamp     0\n",
      "dtype: int64\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Unique values tags' in dataset:\n",
      "73050\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the tags' dataset:\")\n",
    "print(tags_df.info())\n",
    "# Timestamp unnecessary\n",
    "# Tags are user defined, so a lot of them (although the same) will be spelled differently. \n",
    "    # i.e. sci-fi vs scifi, 90's vs 90s, and Horror vs horror\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the tags' dataset:\")\n",
    "print(tags_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the tags' dataset:\", tags_df.shape)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the tags' dataset:\")\n",
    "print(tags_df.isnull().sum())\n",
    "# 16 missing values\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nUnique values tags' in dataset:\")\n",
    "print(tags_df.tag.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Preprocessing for Ratings, and Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n"
     ]
    }
   ],
   "source": [
    "print(ratings_df.head())\n",
    "ratings_cleaned = ratings_df.copy()\n",
    "ratings_cleaned = ratings_cleaned.drop(columns=['timestamp'])\n",
    "ratings_cleaned = ratings_cleaned[ratings_cleaned['rating'] >= 4.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tags(tag):\n",
    "    \"\"\"Preprocess tags by lowercasing, removing parentheses, hyphens, and 'based'.\"\"\"\n",
    "    if pd.isna(tag):\n",
    "        return tag  # Return NaN as is\n",
    "    tag = tag.lower()\n",
    "    tag = re.sub(r'\\(.*?\\)', '', tag)\n",
    "    tag = tag.replace('-', '')\n",
    "    return tag.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId               tag   timestamp\n",
      "0       3      260           classic  1439472355\n",
      "1       3      260            sci-fi  1439472256\n",
      "2       4     1732       dark comedy  1573943598\n",
      "3       4     1732    great dialogue  1573943604\n",
      "4       4     7569  so bad it's good  1573943455\n",
      "   userId  movieId               tag\n",
      "0       3      260           classic\n",
      "1       3      260             scifi\n",
      "2       4     1732       dark comedy\n",
      "3       4     1732    great dialogue\n",
      "4       4     7569  so bad it's good\n"
     ]
    }
   ],
   "source": [
    "tags_cleaned = tags_df.copy()\n",
    "print(tags_df.head())\n",
    "\n",
    "tags_cleaned = tags_cleaned.drop(columns=['timestamp'])\n",
    "tags_cleaned = tags_cleaned.dropna()\n",
    "\n",
    "tags_cleaned['tag'] = tags_cleaned['tag'].apply(preprocess_tags)\n",
    "tags_cleaned = tags_cleaned[~tags_cleaned['tag'].str.contains('based', na=False)]\n",
    "print(tags_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_movies(genre):\n",
    "    \"\"\"Convert genre strings into lowercase.\"\"\"\n",
    "    return genre.lower()  # Make sure to return the processed genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  adventure|animation|children|comedy|fantasy  \n",
      "1                   adventure|children|fantasy  \n",
      "2                               comedy|romance  \n",
      "3                         comedy|drama|romance  \n",
      "4                                       comedy  \n"
     ]
    }
   ],
   "source": [
    "movies_cleaned = movies_df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "print(movies_df.head())\n",
    "\n",
    "movies_cleaned['genres'] = movies_cleaned['genres'].apply(preprocess_movies)\n",
    "print(movies_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets to create Movies-based dataset, movies_genres&tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating initial movies_genres&tags dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                         genres&tags  \n",
      "0  villian hurts toys|dvdvideo|boy|watched|rivalr...  \n",
      "1  joe johnston|new home|time travel|animals|film...  \n",
      "2  fishing|comedy|comedinha de velhinhos engraãƒâ...  \n",
      "3  comedy|romance|divorce|interracial relationshi...  \n",
      "4  comedy|aging|pregnancy|diane keaton|sequel fev...  \n"
     ]
    }
   ],
   "source": [
    "# Merge movies and tags data\n",
    "merged_data = pd.merge(movies_cleaned, tags_cleaned, on='movieId', how='left')\n",
    "def combine_and_deduplicate(group):\n",
    "    # Combine all genres and tags for each group (movie)\n",
    "    all_genres = group['genres'].iloc[0].split('|') if pd.notna(group['genres'].iloc[0]) else []\n",
    "    all_tags = group['tag'].dropna().tolist()\n",
    "    combined = list(set(all_genres + all_tags))  # Remove duplicates\n",
    "    return '|'.join(combined)\n",
    "\n",
    "# Apply the function to each group\n",
    "movies_genres_tags = merged_data.groupby('movieId').apply(combine_and_deduplicate).reset_index(name='genres&tags')\n",
    "\n",
    "# Merge with movies_cleaned to get titles\n",
    "movies_genres_tags = pd.merge(movies_cleaned[['movieId', 'title']], movies_genres_tags, on='movieId')\n",
    "\n",
    "print(movies_genres_tags.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding relevance scores for each genre/tag to the movies-based dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge genome scores and tags\n",
    "genome_combined = pd.merge(genome_scores_df, genome_tags_df, on='tagId')\n",
    "\n",
    "# Creating a dictionary for quick relevance score lookup\n",
    "genome_dict = genome_combined.set_index(['movieId', 'tag'])['relevance'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find relevance scores using the dictionary\n",
    "def find_relevance_scores(row):\n",
    "    genres_tags = row['genres&tags'].split('|')\n",
    "    scores = [genome_dict.get((row['movieId'], tag), 0) for tag in genres_tags]\n",
    "    # Filter out scores below 0.6 and corresponding tags/genres\n",
    "    filtered_data = [(tag, score) for tag, score in zip(genres_tags, scores) if score >= 0.7]\n",
    "    if filtered_data:\n",
    "        filtered_tags, filtered_scores = zip(*filtered_data)\n",
    "        return '|'.join(filtered_tags), ','.join(map(str, filtered_scores))\n",
    "    else:\n",
    "        return '', ''\n",
    "\n",
    "# Apply the function to movies_genres_tags\n",
    "movies_genres_tags[['genres&tags', 'relevance_scores']] = movies_genres_tags.apply(find_relevance_scores, axis=1, result_type='expand')\n",
    "\n",
    "# Save the updated dataset in the data folder\n",
    "movies_genres_tags.to_csv('data/movies_genres&tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets to create users-based dataset, users_liked_genres&tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ratings_cleaned with movies_cleaned\n",
    "user_movies_genres = pd.merge(ratings_cleaned, movies_cleaned, on='movieId')\n",
    "\n",
    "# Merge the above with tags_cleaned\n",
    "user_movies_genres_tags = pd.merge(user_movies_genres, tags_cleaned, on=['userId', 'movieId'], how='left')\n",
    "\n",
    "# Function to concatenate genres and user-specific tags\n",
    "def concatenate_user_genres_tags(group):\n",
    "    genres = '|'.join(group['genres'])\n",
    "    tags = '|'.join(group['tag'].dropna().unique())  # Drop NA and get unique tags\n",
    "    return genres + ('|' + tags if tags else '')  # Combine genres and tags, separated by '|'\n",
    "\n",
    "# Aggregate genres and tags for each user\n",
    "users_liked_genres_tags = user_movies_genres_tags.groupby('userId').apply(concatenate_user_genres_tags).reset_index(name='liked_genres&tags')\n",
    "\n",
    "users_liked_genres_tags.to_csv('data/users_liked_genres&tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding Users with Bias(Used Later for Shallow Evaluations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Comedy Count  Comedy Bias Ratio\n",
      "userId                                 \n",
      "1267               1           1.000000\n",
      "3195              20           1.000000\n",
      "1368              21           0.954545\n",
      "2133              14           0.777778\n",
      "1369              10           0.769231\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the comedy bias ratio for a user\n",
    "def calculate_comedy_bias_ratio(user_genres_tags):\n",
    "    genres_tags_list = user_genres_tags.split('|')\n",
    "    genre_tag_counts = pd.Series(genres_tags_list).value_counts()\n",
    "    comedy_count = genre_tag_counts.get('comedy', 0)\n",
    "    total_count = genre_tag_counts.sum()\n",
    "    # Avoid division by zero in case there are no other genres/tags\n",
    "    bias_ratio = comedy_count / (total_count - comedy_count) if total_count - comedy_count > 0 else 0\n",
    "    return comedy_count, bias_ratio\n",
    "\n",
    "# Limit to the first 10,000 users\n",
    "subset_users = users_liked_genres_tags.head(10000)\n",
    "\n",
    "# Apply the comedy bias ratio calculation to this subset\n",
    "subset_comedy_bias = subset_users.set_index('userId')['liked_genres&tags'].apply(calculate_comedy_bias_ratio)\n",
    "\n",
    "# Create a DataFrame to hold the results for the subset\n",
    "subset_comedy_bias_df = pd.DataFrame(subset_comedy_bias.tolist(), index=subset_comedy_bias.index, columns=['Comedy Count', 'Comedy Bias Ratio'])\n",
    "\n",
    "# Sort the users by their comedy bias ratio in descending order\n",
    "subset_comedy_bias_df = subset_comedy_bias_df.sort_values(by='Comedy Bias Ratio', ascending=False)\n",
    "\n",
    "# Get the top 5 users with the highest comedy bias\n",
    "top_5_comedy_bias_users = subset_comedy_bias_df[subset_comedy_bias_df['Comedy Count'] > 0].head(5)\n",
    "print(top_5_comedy_bias_users)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Calculate the Average for a List Genres/Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading glove Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "glove_file_path = 'data/glove.6B.50d.txt'\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### users_liked_genres&tags embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the average embedding for genres/tags\n",
    "def average_embedding_user(genres_tags, embeddings_index):\n",
    "    embedding_dim = 50\n",
    "    embeddings = []\n",
    "    for phrase in genres_tags.split('|'):\n",
    "        words = phrase.split()\n",
    "        phrase_embeddings = [embeddings_index.get(word, np.zeros(embedding_dim)) for word in words]\n",
    "        embeddings.append(np.mean(phrase_embeddings, axis=0) if phrase_embeddings else np.zeros(embedding_dim))\n",
    "    avg_embedding = np.mean(embeddings, axis=0) if embeddings else np.zeros(embedding_dim)\n",
    "    return avg_embedding\n",
    "\n",
    "# Apply the function to each user\n",
    "users_liked_genres_tags['user_embedding'] = users_liked_genres_tags['liked_genres&tags'].apply(lambda x: average_embedding_user(x, glove_embeddings))\n",
    "users_liked_genres_tags.to_csv('data/users_liked_genres&tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movies_genres&tags embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the weighted average embedding for movies\n",
    "def average_embedding_movie(genres_tags, relevance_scores, embeddings_index):\n",
    "    embedding_dim = 50\n",
    "    genres_tags_list = genres_tags.split('|')\n",
    "    scores_list = relevance_scores.split(',') if relevance_scores else [1] * len(genres_tags_list)\n",
    "    weighted_embeddings = []\n",
    "    for tag, score in zip(genres_tags_list, scores_list):\n",
    "        words = tag.split()\n",
    "        phrase_embeddings = [embeddings_index.get(word, np.zeros(embedding_dim)) for word in words]\n",
    "        avg_phrase_embedding = np.mean(phrase_embeddings, axis=0) if phrase_embeddings else np.zeros(embedding_dim)\n",
    "        weighted_embeddings.append(avg_phrase_embedding * float(score))\n",
    "    avg_embedding = np.mean(weighted_embeddings, axis=0) if weighted_embeddings else np.zeros(embedding_dim)\n",
    "    return avg_embedding\n",
    "\n",
    "# Apply the function to each movie\n",
    "movies_genres_tags['movie_embedding'] = movies_genres_tags.apply(lambda x: average_embedding_movie(x['genres&tags'], x['relevance_scores'], glove_embeddings), axis=1)\n",
    "movies_genres_tags.to_csv('data/movies_genres&tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our KNN Model and Testing with Specific User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "movie_embeddings = np.stack(movies_genres_tags['movie_embedding'].values)\n",
    "user_embedding_3195 = users_liked_genres_tags.loc[users_liked_genres_tags['userId'] == 3195, 'user_embedding'].values[0]\n",
    "\n",
    "# Build the KNN model\n",
    "# Set KNN to 10,000 neighbors\n",
    "knn = NearestNeighbors(n_neighbors=10000, metric='cosine')\n",
    "knn.fit(movie_embeddings)\n",
    "\n",
    "# Query the model for user 3195\n",
    "_, indices_3195 = knn.kneighbors([user_embedding_3195])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total movies watched and liked by User 3195: 20\n",
      "Hits@k for User 3195:\n",
      "hits@10: 0\n",
      "hits@100: 0\n",
      "hits@1000: 3\n",
      "hits@10000: 19\n",
      "\n",
      "Top 10 movie recommendations for User 3195:\n",
      "1. Blast from the Past (1999)\n",
      "2. Mr. Saturday Night (1992)\n",
      "3. Punchline (1988)\n",
      "4. Head Over Heels (2001)\n",
      "5. America's Sweethearts (2001)\n",
      "6. Guarding Tess (1994)\n",
      "7. Bachelor Mother (1939)\n",
      "8. Roxanne (1987)\n",
      "9. More the Merrier, The (1943)\n",
      "10. $5 a Day (2008)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get the recommended movie IDs for different values of k\n",
    "recommended_ids_at_k = {\n",
    "    '10': set(movies_genres_tags.iloc[indices_3195[0][:10]]['movieId'].values),\n",
    "    '100': set(movies_genres_tags.iloc[indices_3195[0][:100]]['movieId'].values),\n",
    "    '1000': set(movies_genres_tags.iloc[indices_3195[0][:1000]]['movieId'].values),\n",
    "    '10000': set(movies_genres_tags.iloc[indices_3195[0]]['movieId'].values)\n",
    "}\n",
    "\n",
    "# User 3195's originally liked movies\n",
    "user_3195_liked_movies = set(ratings_cleaned[ratings_cleaned['userId'] == 3195]['movieId'].values)\n",
    "\n",
    "# Calculate the total number of movies user 3195 has watched and liked\n",
    "total_watched_by_3195 = len(user_3195_liked_movies)\n",
    "print(f\"Total movies watched and liked by User 3195: {total_watched_by_3195}\")\n",
    "\n",
    "# Calculate hits@k\n",
    "hits_at_k = {k: len(user_3195_liked_movies & recommended_ids) for k, recommended_ids in recommended_ids_at_k.items()}\n",
    "\n",
    "# Print hits@k results\n",
    "print(\"Hits@k for User 3195:\")\n",
    "for k, hits in hits_at_k.items():\n",
    "    print(f\"hits@{k}: {hits}\")\n",
    "\n",
    "# Print the top 10 recommended movies\n",
    "top_10_recommended_titles = movies_genres_tags[movies_genres_tags['movieId'].isin(recommended_ids_at_k['10'])]['title'].values\n",
    "print(\"\\nTop 10 movie recommendations for User 3195:\")\n",
    "for i, title in enumerate(top_10_recommended_titles, start=1):\n",
    "    print(f\"{i}. {title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Old Embedding and KNN implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nembedding_dim = 50\\n\\ndef average_embedding_user(words_to_embed, glove_embeddings, embedding_dim):\\n    return np.mean([glove_embeddings.get(word,np.zeros(embedding_dim)) for word in words_to_embed])\\n\\ndef average_embedding_movie(words_to_embed, glove_embeddings, embedding_dim, relevance_scores):\\n\\n    embeddings = []\\n\\n    for i, word in enumerate(words_to_embed):\\n        for j in range(len(relevance_scores[i])):\\n            embeddings.append(relevance_scores[i][j] * glove_embeddings.get(word, np.zeros(embedding_dim)))\\n\\n    avg_embedding = np.mean(embeddings, axis=0)\\n    return avg_embedding\\n\\n\\n#creates 2d array for multiplying releavance scores with embedding\\ndef unpacking_relevance_score(relevance_scores):\\n\\n    res = []\\n  \\n    for total_score in relevance_scores:\\n        if total_score == '':\\n            res.append([])\\n            continue\\n        total_score =  total_score.split(',')\\n        total_score = np.array([float(single_score)for single_score in total_score])\\n        res.append(total_score)\\n    return res\\n\\nrelevance_scores = unpacking_relevance_score(movies_genres_tags['relevance_scores'].values)\\n\\n# Apply the function to calculate average embeddings for each movie\\nmovies_genres_tags['movie_embedding'] = movies_genres_tags['genres&tags'].apply(\\n    lambda x: average_embedding_movie(x.split('|'), glove_embeddings, embedding_dim, relevance_scores)\\n)\\n\\nusers_liked_genres_tags['user_embedding'] = users_liked_genres_tags['liked_genres&tags'].apply(\\n    lambda x: average_embedding_user(x.split('|'), glove_embeddings, embedding_dim)\\n)\\n\\nusers_liked_genres_tags.to_csv('data/users_liked_genres&tags.csv', index=False)\\nmovies_genres_tags.to_csv('data/movies_genres&tags.csv', index=False)\\nratings_over_4.to_csv('data/ratings_over_4.csv', index=False)\\n\""
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "embedding_dim = 50\n",
    "\n",
    "def average_embedding_user(words_to_embed, glove_embeddings, embedding_dim):\n",
    "    return np.mean([glove_embeddings.get(word,np.zeros(embedding_dim)) for word in words_to_embed])\n",
    "\n",
    "def average_embedding_movie(words_to_embed, glove_embeddings, embedding_dim, relevance_scores):\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for i, word in enumerate(words_to_embed):\n",
    "        for j in range(len(relevance_scores[i])):\n",
    "            embeddings.append(relevance_scores[i][j] * glove_embeddings.get(word, np.zeros(embedding_dim)))\n",
    "\n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    return avg_embedding\n",
    "\n",
    "\n",
    "#creates 2d array for multiplying releavance scores with embedding\n",
    "def unpacking_relevance_score(relevance_scores):\n",
    "\n",
    "    res = []\n",
    "  \n",
    "    for total_score in relevance_scores:\n",
    "        if total_score == '':\n",
    "            res.append([])\n",
    "            continue\n",
    "        total_score =  total_score.split(',')\n",
    "        total_score = np.array([float(single_score)for single_score in total_score])\n",
    "        res.append(total_score)\n",
    "    return res\n",
    "\n",
    "relevance_scores = unpacking_relevance_score(movies_genres_tags['relevance_scores'].values)\n",
    "\n",
    "# Apply the function to calculate average embeddings for each movie\n",
    "movies_genres_tags['movie_embedding'] = movies_genres_tags['genres&tags'].apply(\n",
    "    lambda x: average_embedding_movie(x.split('|'), glove_embeddings, embedding_dim, relevance_scores)\n",
    ")\n",
    "\n",
    "users_liked_genres_tags['user_embedding'] = users_liked_genres_tags['liked_genres&tags'].apply(\n",
    "    lambda x: average_embedding_user(x.split('|'), glove_embeddings, embedding_dim)\n",
    ")\n",
    "\n",
    "users_liked_genres_tags.to_csv('data/users_liked_genres&tags.csv', index=False)\n",
    "movies_genres_tags.to_csv('data/movies_genres&tags.csv', index=False)\n",
    "ratings_over_4.to_csv('data/ratings_over_4.csv', index=False)\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nsample_movies = np.array(movies_genres_tags[\\'title\\'].values)\\n\\n# Stack movie embeddings into a 2D array\\nX_sample = np.vstack(movies_genres_tags[\\'movie_embedding\\'].values)\\n\\nuser_movie_ids = ratings_over_4.groupby(\\'userId\\')[\\'movieId\\'].unique()\\n\\n#now we need to use the movieID to reference \"movie_embedding\" in my \"movies_generes_tags\",\\nuser_embeddings = []\\nuser_movies = []\\nfor movie_ids in user_movie_ids:\\n    movie_embeddings = [movies_genres_tags.loc[movies_genres_tags[\\'movieId\\'] == movie_id, \\'movie_embedding\\'].values[0]\\n                        for movie_id in movie_ids]\\n    user_embedding = np.mean(movie_embeddings, axis=0)\\n    user_embeddings.append(user_embedding)\\n\\n    movie_names = [movies_genres_tags.loc[movies_genres_tags[\\'movieId\\'] == movie_id, \\'title\\'].values[0]\\n                   for movie_id in movie_ids]\\n    user_movies.append(movie_names)\\n\\nX_user = np.array(user_embeddings)\\n\\n\\n\\n# Get user embeddings\\n\\n# Create and fit the model with cosine similarity using 4 closest movies\\nknn = NearestNeighbors(n_neighbors=10, metric=\\'cosine\\')\\nknn.fit(X_sample)\\n\\n\\n #Find 4 movies similar to the query movie\\nrecommendations = []\\nfor test in X_user:\\n    distances, indices = knn.kneighbors([test])\\n\\n    # Filter out movies that are already liked by the user\\n    similar_movies = [sample_movies[i] for i in indices[0] if sample_movies[i] not in user_movies]\\n    recommendations.append(similar_movies)\\n\\n# Print the similar movies\\nfor i, user_movie in enumerate(user_movies):\\n    print(f\"Based on {user_movie}, we would recommend:\")\\n    for recommended_movie in recommendations[i]:\\n        print(recommended_movie)\\n    print()\\n'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sample_movies = np.array(movies_genres_tags['title'].values)\n",
    "\n",
    "# Stack movie embeddings into a 2D array\n",
    "X_sample = np.vstack(movies_genres_tags['movie_embedding'].values)\n",
    "\n",
    "user_movie_ids = ratings_over_4.groupby('userId')['movieId'].unique()\n",
    "\n",
    "#now we need to use the movieID to reference \"movie_embedding\" in my \"movies_generes_tags\",\n",
    "user_embeddings = []\n",
    "user_movies = []\n",
    "for movie_ids in user_movie_ids:\n",
    "    movie_embeddings = [movies_genres_tags.loc[movies_genres_tags['movieId'] == movie_id, 'movie_embedding'].values[0]\n",
    "                        for movie_id in movie_ids]\n",
    "    user_embedding = np.mean(movie_embeddings, axis=0)\n",
    "    user_embeddings.append(user_embedding)\n",
    "\n",
    "    movie_names = [movies_genres_tags.loc[movies_genres_tags['movieId'] == movie_id, 'title'].values[0]\n",
    "                   for movie_id in movie_ids]\n",
    "    user_movies.append(movie_names)\n",
    "\n",
    "X_user = np.array(user_embeddings)\n",
    "\n",
    "\n",
    "\n",
    "# Get user embeddings\n",
    "\n",
    "# Create and fit the model with cosine similarity using 4 closest movies\n",
    "knn = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "knn.fit(X_sample)\n",
    "\n",
    "\n",
    " #Find 4 movies similar to the query movie\n",
    "recommendations = []\n",
    "for test in X_user:\n",
    "    distances, indices = knn.kneighbors([test])\n",
    "\n",
    "    # Filter out movies that are already liked by the user\n",
    "    similar_movies = [sample_movies[i] for i in indices[0] if sample_movies[i] not in user_movies]\n",
    "    recommendations.append(similar_movies)\n",
    "\n",
    "# Print the similar movies\n",
    "for i, user_movie in enumerate(user_movies):\n",
    "    print(f\"Based on {user_movie}, we would recommend:\")\n",
    "    for recommended_movie in recommendations[i]:\n",
    "        print(recommended_movie)\n",
    "    print()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
