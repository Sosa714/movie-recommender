{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommendation System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports and Constants Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"movies.csv\"))\n",
    "ratings_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"ratings.csv\")).iloc[:500000, :] # Using 500,000 for now due to sheer size of original\n",
    "tags_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"tags.csv\"))\n",
    "genome_scores_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"genome-scores.csv\"))\n",
    "genome_tags_df = pd.read_csv(os.path.join(os.getcwd(), 'data', \"genome-tags.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the movies' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 62423 entries, 0 to 62422\n",
      "Data columns (total 3 columns):\n",
      " #   Column   Non-Null Count  Dtype \n",
      "---  ------   --------------  ----- \n",
      " 0   movieId  62423 non-null  int64 \n",
      " 1   title    62423 non-null  object\n",
      " 2   genres   62423 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the movies' dataset:\n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the movies' dataset: (62423, 3)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the movies' dataset:\n",
      "movieId    0\n",
      "title      0\n",
      "genres     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the movies' dataset:\")\n",
    "print(movies_df.info())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the movies' dataset:\")\n",
    "print(movies_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the movies' dataset:\", movies_df.shape)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the movies' dataset:\")\n",
    "print(movies_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the ratings' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count   Dtype  \n",
      "---  ------     --------------   -----  \n",
      " 0   userId     500000 non-null  int64  \n",
      " 1   movieId    500000 non-null  int64  \n",
      " 2   rating     500000 non-null  float64\n",
      " 3   timestamp  500000 non-null  int64  \n",
      "dtypes: float64(1), int64(3)\n",
      "memory usage: 15.3 MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the ratings' dataset:\n",
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the ratings' dataset: (500000, 4)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the ratings' dataset:\n",
      "userId       0\n",
      "movieId      0\n",
      "rating       0\n",
      "timestamp    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the ratings' dataset:\")\n",
    "print(ratings_df.info())\n",
    "# Timestamp unnecessary\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the ratings' dataset:\")\n",
    "print(ratings_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the ratings' dataset:\", ratings_df.shape)\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the ratings' dataset:\")\n",
    "print(ratings_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "General information of the tags' dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1093360 entries, 0 to 1093359\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count    Dtype \n",
      "---  ------     --------------    ----- \n",
      " 0   userId     1093360 non-null  int64 \n",
      " 1   movieId    1093360 non-null  int64 \n",
      " 2   tag        1093344 non-null  object\n",
      " 3   timestamp  1093360 non-null  int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 33.4+ MB\n",
      "None\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Head of the tags' dataset:\n",
      "   userId  movieId               tag   timestamp\n",
      "0       3      260           classic  1439472355\n",
      "1       3      260            sci-fi  1439472256\n",
      "2       4     1732       dark comedy  1573943598\n",
      "3       4     1732    great dialogue  1573943604\n",
      "4       4     7569  so bad it's good  1573943455\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Shape of the tags' dataset: (1093360, 4)\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Missing values of the tags' dataset:\n",
      "userId        0\n",
      "movieId       0\n",
      "tag          16\n",
      "timestamp     0\n",
      "dtype: int64\n",
      "------------------------------------------------------------------\n",
      "\n",
      "Unique values tags' in dataset:\n",
      "73050\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGeneral information of the tags' dataset:\")\n",
    "print(tags_df.info())\n",
    "# Timestamp unnecessary\n",
    "# Tags are user defined, so a lot of them (although the same) will be spelled differently. \n",
    "    # i.e. sci-fi vs scifi, 90's vs 90s, and Horror vs horror\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nHead of the tags' dataset:\")\n",
    "print(tags_df.head())\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nShape of the tags' dataset:\", tags_df.shape)\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nMissing values of the tags' dataset:\")\n",
    "print(tags_df.isnull().sum())\n",
    "# 16 missing values\n",
    "\n",
    "print(\"------------------------------------------------------------------\")\n",
    "\n",
    "print(\"\\nUnique values tags' in dataset:\")\n",
    "print(tags_df.tag.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data Preprocessing for Ratings, and Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ratings Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId  rating   timestamp\n",
      "0       1      296     5.0  1147880044\n",
      "1       1      306     3.5  1147868817\n",
      "2       1      307     5.0  1147868828\n",
      "3       1      665     5.0  1147878820\n",
      "4       1      899     3.5  1147868510\n",
      "   userId  movieId  rating\n",
      "0       1      296     5.0\n",
      "2       1      307     5.0\n",
      "3       1      665     5.0\n",
      "5       1     1088     4.0\n",
      "8       1     1237     5.0\n"
     ]
    }
   ],
   "source": [
    "print(ratings_df.head())\n",
    "ratings_cleaned = ratings_df.copy()\n",
    "ratings_cleaned = ratings_cleaned.drop(columns=['timestamp'])\n",
    "ratings_cleaned = ratings_cleaned[ratings_cleaned['rating'] >= 4.0]\n",
    "\n",
    "\n",
    "##used later for figuring out what movies a user will like\n",
    "ratings_over_4 = ratings_cleaned.copy(deep = True)\n",
    "\n",
    "\n",
    "print(ratings_cleaned.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_tags(tag):\n",
    "    \"\"\"Preprocess tags by lowercasing, removing parentheses, hyphens, and 'based'.\"\"\"\n",
    "    if pd.isna(tag):\n",
    "        return tag  # Return NaN as is\n",
    "    tag = tag.lower()\n",
    "    tag = re.sub(r'\\(.*?\\)', '', tag)\n",
    "    tag = tag.replace('-', '')\n",
    "    return tag.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   userId  movieId               tag   timestamp\n",
      "0       3      260           classic  1439472355\n",
      "1       3      260            sci-fi  1439472256\n",
      "2       4     1732       dark comedy  1573943598\n",
      "3       4     1732    great dialogue  1573943604\n",
      "4       4     7569  so bad it's good  1573943455\n",
      "   userId  movieId               tag\n",
      "0       3      260           classic\n",
      "1       3      260             scifi\n",
      "2       4     1732       dark comedy\n",
      "3       4     1732    great dialogue\n",
      "4       4     7569  so bad it's good\n"
     ]
    }
   ],
   "source": [
    "tags_cleaned = tags_df.copy()\n",
    "print(tags_df.head())\n",
    "\n",
    "tags_cleaned = tags_cleaned.drop(columns=['timestamp'])\n",
    "tags_cleaned = tags_cleaned.dropna()\n",
    "\n",
    "tags_cleaned['tag'] = tags_cleaned['tag'].apply(preprocess_tags)\n",
    "tags_cleaned = tags_cleaned[~tags_cleaned['tag'].str.contains('based', na=False)]\n",
    "print(tags_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movies Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_movies(genre):\n",
    "    \"\"\"Convert genre strings into lowercase.\"\"\"\n",
    "    return genre.lower()  # Make sure to return the processed genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
      "1                   Adventure|Children|Fantasy  \n",
      "2                               Comedy|Romance  \n",
      "3                         Comedy|Drama|Romance  \n",
      "4                                       Comedy  \n",
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                        genres  \n",
      "0  adventure|animation|children|comedy|fantasy  \n",
      "1                   adventure|children|fantasy  \n",
      "2                               comedy|romance  \n",
      "3                         comedy|drama|romance  \n",
      "4                                       comedy  \n"
     ]
    }
   ],
   "source": [
    "movies_cleaned = movies_df.copy()  # Create a copy to avoid modifying the original DataFrame\n",
    "print(movies_df.head())\n",
    "\n",
    "movies_cleaned['genres'] = movies_cleaned['genres'].apply(preprocess_movies)\n",
    "print(movies_cleaned.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets to create Movies-based dataset, movies_genres&tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating initial movies_genres&tags dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   movieId                               title  \\\n",
      "0        1                    Toy Story (1995)   \n",
      "1        2                      Jumanji (1995)   \n",
      "2        3             Grumpier Old Men (1995)   \n",
      "3        4            Waiting to Exhale (1995)   \n",
      "4        5  Father of the Bride Part II (1995)   \n",
      "\n",
      "                                         genres&tags  \n",
      "0  cartoon|want to see again|toys come to life|it...  \n",
      "1  time travel|new home|not for kids|robin willia...  \n",
      "2  ann margaret|funny|sequel fever|comedinha de v...  \n",
      "3  comedy|chick flick|revenge|divorce|drama|chara...  \n",
      "4  baby|daughter|sequel fever|pregnancy|family|gy...  \n"
     ]
    }
   ],
   "source": [
    "# Merge movies and tags data\n",
    "merged_data = pd.merge(movies_cleaned, tags_cleaned, on='movieId', how='left')\n",
    "def combine_and_deduplicate(group):\n",
    "    # Combine all genres and tags for each group (movie)\n",
    "    all_genres = group['genres'].iloc[0].split('|') if pd.notna(group['genres'].iloc[0]) else []\n",
    "    all_tags = group['tag'].dropna().tolist()\n",
    "    combined = list(set(all_genres + all_tags))  # Remove duplicates\n",
    "    return '|'.join(combined)\n",
    "\n",
    "# Apply the function to each group\n",
    "movies_genres_tags = merged_data.groupby('movieId').apply(combine_and_deduplicate).reset_index(name='genres&tags')\n",
    "\n",
    "# Merge with movies_cleaned to get titles\n",
    "movies_genres_tags = pd.merge(movies_cleaned[['movieId', 'title']], movies_genres_tags, on='movieId')\n",
    "\n",
    "print(movies_genres_tags.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding relevance scores for each genre/tag to the movies-based dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge genome scores and tags\n",
    "genome_combined = pd.merge(genome_scores_df, genome_tags_df, on='tagId')\n",
    "\n",
    "# Creating a dictionary for quick relevance score lookup\n",
    "genome_dict = genome_combined.set_index(['movieId', 'tag'])['relevance'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find relevance scores using the dictionary\n",
    "def find_relevance_scores(row):\n",
    "    genres_tags = row['genres&tags'].split('|')\n",
    "    scores = [genome_dict.get((row['movieId'], tag), 0) for tag in genres_tags]\n",
    "    # Filter out scores below 0.6 and corresponding tags/genres\n",
    "    filtered_data = [(tag, score) for tag, score in zip(genres_tags, scores) if score >= 0.7]\n",
    "    if filtered_data:\n",
    "        filtered_tags, filtered_scores = zip(*filtered_data)\n",
    "        return '|'.join(filtered_tags), ','.join(map(str, filtered_scores))\n",
    "    else:\n",
    "        return '', ''\n",
    "\n",
    "# Apply the function to movies_genres_tags\n",
    "movies_genres_tags[['genres&tags', 'relevance_scores']] = movies_genres_tags.apply(find_relevance_scores, axis=1, result_type='expand')\n",
    "\n",
    "# Save the updated dataset in the data folder\n",
    "movies_genres_tags.to_csv('data/movies_genres&tags.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging datasets to create users-based dataset, users_liked_genres&tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge ratings_cleaned with movies_cleaned\n",
    "user_movies_genres = pd.merge(ratings_cleaned, movies_cleaned, on='movieId')\n",
    "\n",
    "# Merge the above with tags_cleaned\n",
    "user_movies_genres_tags = pd.merge(user_movies_genres, tags_cleaned, on=['userId', 'movieId'], how='left')\n",
    "\n",
    "# Function to concatenate genres and user-specific tags\n",
    "def concatenate_user_genres_tags(group):\n",
    "    genres = '|'.join(group['genres'])\n",
    "    tags = '|'.join(group['tag'].dropna().unique())  # Drop NA and get unique tags\n",
    "    return genres + ('|' + tags if tags else '')  # Combine genres and tags, separated by '|'\n",
    "\n",
    "# Aggregate genres and tags for each user\n",
    "users_liked_genres_tags = user_movies_genres_tags.groupby('userId').apply(concatenate_user_genres_tags).reset_index(name='liked_genres&tags')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading GloVe Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove_embeddings(file_path):\n",
    "    embeddings_index = {}\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            values = line.split()\n",
    "            word = values[0]\n",
    "            vector = np.asarray(values[1:], dtype='float32')\n",
    "            embeddings_index[word] = vector\n",
    "    return embeddings_index\n",
    "\n",
    "glove_file_path = 'data/glove.6B.50d.txt'\n",
    "glove_embeddings = load_glove_embeddings(glove_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function To calculate the average for a list of embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embedding_dim = 50\n",
    "\n",
    "def average_embedding_user(words_to_embed, glove_embeddings, embedding_dim):\n",
    "    return np.mean([glove_embeddings.get(word,np.zeros(embedding_dim)) for word in words_to_embed])\n",
    "\n",
    "def average_embedding_movie(words_to_embed, glove_embeddings, embedding_dim, relevance_scores):\n",
    "\n",
    "    embeddings = []\n",
    "\n",
    "    for i, word in enumerate(words_to_embed):\n",
    "        for j in range(len(relevance_scores[i])):\n",
    "            embeddings.append(relevance_scores[i][j] * glove_embeddings.get(word, np.zeros(embedding_dim)))\n",
    "\n",
    "    avg_embedding = np.mean(embeddings, axis=0)\n",
    "    return avg_embedding\n",
    "\n",
    "\n",
    "#creates 2d array for multiplying releavance scores with embedding\n",
    "def unpacking_relevance_score(relevance_scores):\n",
    "\n",
    "    res = []\n",
    "  \n",
    "    for total_score in relevance_scores:\n",
    "        if total_score == '':\n",
    "            res.append([])\n",
    "            continue\n",
    "        total_score =  total_score.split(',')\n",
    "        total_score = np.array([float(single_score)for single_score in total_score])\n",
    "        res.append(total_score)\n",
    "    return res\n",
    "\n",
    "relevance_scores = unpacking_relevance_score(movies_genres_tags['relevance_scores'].values)\n",
    "\n",
    "# Apply the function to calculate average embeddings for each movie\n",
    "movies_genres_tags['movie_embedding'] = movies_genres_tags['genres&tags'].apply(\n",
    "    lambda x: average_embedding_movie(x.split('|'), glove_embeddings, embedding_dim, relevance_scores)\n",
    ")\n",
    "\n",
    "users_liked_genres_tags['user_embedding'] = users_liked_genres_tags['liked_genres&tags'].apply(\n",
    "    lambda x: average_embedding_user(x.split('|'), glove_embeddings, embedding_dim)\n",
    ")\n",
    "\n",
    "users_liked_genres_tags.to_csv('data/users_liked_genres&tags.csv', index=False)\n",
    "movies_genres_tags.to_csv('data/movies_genres&tags.csv', index=False)\n",
    "ratings_over_4.to_csv('data/ratings_over_4.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1585400169.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[78], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    while\u001b[0m\n\u001b[1;37m          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "movies = np.array(movies_genres_tags['title'].values)\n",
    "\n",
    "# Stack movie embeddings into a 2D array\n",
    "X_sample = np.vstack(movies_genres_tags['movie_embedding'].values)\n",
    "#go thru every movieid a user rated in \"ratings_over_4 which\" is a dataframe like\n",
    "#need to g\n",
    "while \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Get user embeddings\n",
    "user_movie_embeddings = np.array(users_liked_genres_tags['user_embedding'].values)\n",
    "\n",
    "# Create and fit the model with cosine similarity using 10 closest movies\n",
    "knn = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "knn.fit(X_sample)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
